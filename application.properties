[global]

# config_dir:
# Directory where configuration file will be stored
#   default = ###USER###/.dgenies
#
config_dir = ###USER###/.dgenies

# upload_folder:
# Directory where uploaded files will be stored.
#   default = /tmp/dgenies
#
upload_folder = /tmp/dgenies

# data_folder:
# Directory where data files will be stored (PAF files and other files used for the dotplot)
#   default = ###CONFIG###/data
#
data_folder = ###CONFIG###/data

# runner_type:
# Webserver mode only, define if D-Genies runs jobs locally or send them to a cluster.
#   possible values:
#       - local: run all jobs locally,
#       - sge: SGE job scheduler,
#       - slurm: slurm job scheduler
#   default = local
#
runner_type = local

# web_url:
# Public URL of your D-Genies website.
#   default = http://localhost:5000
#
web_url = http://localhost:5000

# max_upload_size:
# Max size of uploaded files (also for files from URL, size uncompressed):
# Please set the unit: M for Megabyte or G for Gigabyte (-1 without unit to don't set a limit)
#   default = -1
#
max_upload_size = 3G

# max_upload_size_ava:
# Max upload file size for all-vs-all (only target):
# Please set the unit: M for Megabyte or G for Gigabyte (-1 without unit to don't set a limit)
#   default = -1
#
max_upload_size_ava = 1G

# max_upload_file_size:
# Max upload file size (compressed or not, only for uploaded files, not from URL):
# Please set the unit: M for Megabyte or G for Gigabyte (-1 without unit to don't set a limit)
#   default = 1G
#
max_upload_file_size = 1G

# max_nb_lines:
# Maximum number of lines read and displayed for paf file
#   default: 100000
#
max_nb_lines = 100000

# max_nb_jobs_in_batch_mode:
# Maximum number of jobs allowed for batch mode
#   default: 10
#
max_nb_jobs_in_batch_mode = 10

[debug]
# debug:
# For testing and debugging only, do not use those options in production.

# debug.enable:
# Enable debugging mode
#   default = False
#
enable = False

# debug.log_dir:
# Directory where log files must be stored
#   default = ###CONFIG###/logs
#
log_dir = ###CONFIG###/logs

# debug.allowed_ip_tests:
# IP allowed to connect to D-Genies in test mode.
#   default = 127.0.0.1
#
allowed_ip_tests =

[cluster]
# cluster:
# Entries to configure D-Genies with a cluster by using DRMAA library with slurm or SGE.
# Only slurm is currently tested.
# Ignored if 'runner_type' in [global] section is set to 'local'.

# cluster.drmaa_lib_path:
# Path to DRMAA library. The path must be set when 'runner_type' is not 'local'.
# The path must be the same on D-Genies server and cluster nodes
# Tested with slurm-drmmaa.
#   default = ###SET_IT###
#
drmaa_lib_path = ###SET_IT###

# cluster.native_specs:
# Options passed to the scheduler. By default D-Genies is set as:
#   - Slurm: --mem-per-cpu={0} --nodes=1 --mincpus={1} --time={2}
#   - SGE: -l mem={0},h_vmem={0} -pe parallel_smp {1}
#
# Note: copy&paste specifications for your scheduler. You can customize it.
# Always use {0} for memory, {1} for number of CPUs ({2} for duration time if slurm). All are required.
# If you don't want to change anything, don't edit anything.
#   default = ###DEFAULT###
#
native_specs = ###DEFAULT###

# cluster.max_run_local:
# If runner_type is not local, small jobs can be still run locally.
# Max number of jobs running locally.
# If this number is reached, future jobs will be submitted to the cluster regardless of their size.
# Set to 0 to run all jobs on the cluster
#   default = 10
#
max_run_local = 10

# cluster.max_wait_local:
# If runner_type is not local, small jobs can be still run locally.
# Max number of jobs waiting for a local run.
# If this number is reached, future jobs will be submitted to the cluster regardless of their size.
# Set to 0 to run all jobs on the cluster.
#   default = 5
#
max_wait_local = 5

# cluster.min_query_size & cluster.min_target_size:
# To run only big jobs on the cluster, set the min query and target size (uncompressed).
# If max_run_local is reached, these parameters are ignores.
# Default parameters set here is for jobs that runs in approx. more than 3-4 minutes and consume approx. more than 9 GO of RAM
# Please set the unit: M for Megabyte or G for Gigabyte
#   default for both if not set = 0
#
min_query_size = 500M
min_target_size = 700M

# cluster.prepare_script:
# Absolute path to the all_prepare.py script.
# Other D-Genies following scripts must be in the same directory
# as all_prepare.py: filter_contigs.py, index.py and split_fa.py
#   default = "###PROGRAM###/bin/all_prepare.py
#
prepare_script = ###PROGRAM###/bin/all_prepare.py

# cluster.python3_exec:
# Path to python3 executable on the cluster.
# The python environment must contain modules listed in requirements-node.txt
#   default = python3
#
python3_exec = python3

# cluster.memory
# Max memory in GiB to reserve on the cluster.
#   default = 32
#
memory = 32

# cluster.memory_ava
# Max memory in GiB to reserve on the cluster in all-vs-all mode
# Should be higher than memory.
#   default: same as memory
#
memory_ava = 32

# cluster.walltime:
# Maximum running time allowed for any job step.
# Only used with slurm. For SGE, you must configure the queue directly.
# Format "hh:mm:ss"
#   default: "02:00:00"
#
#walltime_prepare = 02:00:00
walltime = 02:00:00

# cluster.walltime_prepare:
# Maximum running time allowed for a prepare step.
# Only used with slurm. For SGE, you must configure the queue directly.
# Format "hh:mm:ss"
#   default: same as walltime
#
#walltime_prepare = 02:00:00

# cluster.walltime_align:
# Maximum running time allowed for an align step.
# Only used with slurm. For SGE, you must configure the queue directly.
# Format is hh:mm:ss
#   default: same as walltime
#
#walltime_align = 02:00:00

[database]
# database:
# In this section, we configure the database that stores the job metadata.
# In webserver mode, database is also used by local_scheduler in order to manage jobs.

# database.type:
# Database engine used for storing job metadata.
#   possible values:
#       - sqlite: sqlite3,
#       - mysql: mariadb or mysql
#  We recommend mariadb/mysql for better performances. This option needs to install mysqlclient.
#   default = sqlite
#
type = sqlite

# database.url:
# Path/url to database.
#   - Path to the sqlite file if type=sqlite.
#   - Url to the mysql server if type=mysql (localhost if the mysql server is on the same machine).
#
#   default = ###USER###/.dgenies/database.sqlite
#
url = ###USER###/.dgenies/database.sqlite

# database.port:
# Port to connect to mariadb or mysql.
# Ignored when using for sqlite.
#   default = 3306
#
port = 3306

# database.db:
# Name of the database.
# Ignored when using for sqlite.
#   no default.
#
db =

# database.user:
# Username to connect to the database.
# Ignored when using for sqlite.
#   no default.
#
user =

# database.password:
# Password to connect to the database.
# Ignored when using for sqlite.
#   no default.
#
password =

[session]
# Session

# max_download_sessions:
# Maximum number of download sessions (one session per job) for downloading distant data (if user gives url as input).
# Allowed sessions will the `max_download_sessions` first ones, Pending sessions will be the remaining ones
#   default: 5
#
max_download_sessions = 5

# delete_allowed_session_delay:
# Webserver mode only, delay in second since last ping before deleting a session
#   default: 50
#
# delete_allowed_session_delay = 50

# reset_pending_session_delay:
# Webserver mode only, delay in second since last ping before resetting a session
#   default: 30
#
# reset_pending_session_delay = 30

# delete_session_delay:
# Webserver mode only, delay in second since last ping before deleting a session
#   default: 86400  # Session has more than 1 day
#
# delete_pending_session_delay = 86400

[mail]
# mail:
# In this section, we configure email. It only concerns the webserver mode.

# mail.status:
# Email address to use as 'from' in the status mail.
# Ignored in standalone mode.
#   default = mail@dgenies
#
status = mail@dgenies

# mail.reply:
# Email address to use as 'reply to' in the status mail.
# Ignored in standalone mode.
#   default = mail@dgenies
#
reply = mail@dgenies

# mail.org:
# Name of the organisation who send the mail, used in email signature.
# Ignored in standalone mode.
#   no default
#
org = "Dgenies team"

# mail.send_mail_status:
# Send status email when set to True.
#   possible values: True, False
# Should be True in production.
# Ignored in standalone mode.
#   default: True
send_mail_status = True

# mail.disable:
# Debugging option for email.
# Display email in logs instead of sending email when set to True.
#   possible values: True, False
# Should be True in production.
# Ignored in standalone mode.
#   default: False
#
# disable = False

[cron]
# cron:
# In this section, we automate the cleaning by setting cron tasks.
# It only the webserver mode.

# cron.clean_time:
# Set time to launch the cron.
# Format is 'nnhmm' where:
#   - 'nn' is the hours, no left 0 padding is needed.
#   - 'mm' are minutes with left 0 padding if needed.
#   - h is the separator between hours and minutes
# Ignored in standalone mode.
#   default = 1h00
#
clean_time = 1h00

# cron.clean_freq:
# Set frequency of cleaning in days
# Ignored in standalone mode.
#   default = 1
#
clean_freq = 1

[jobs]
# jobs:
# Set parameters for number of parallel runs for local jobs.
# This section concerns only the webserver mode.

# jobs.local:
# Max number of concurrent jobs launched locally.
# Ignored in standalone mode.
#   default = 1
#
run_local = 1

# jobs.data_prepare:
# Max number of data prepare jobs launched locally.
# Ignored in standalone mode.
#   default = 2
#
data_prepare = 2

# jobs.max_concurrent_dl:
# Max number of concurrent upload of files allowed.
# Ignored in standalone mode.
#   default = 5
#
max_concurrent_dl = 5

[example]
# example:
# Set a set of example data.
# This section concerns only the webserver mode.
# At least target is required to enable example data.

# example.query:
# Set the absolute local path of the fasta file that will be used as query file
#   no default
#
# query =

# example.target:
# Set the absolute local path of the fasta file that will be used as target file
#   no default
#
# target =

# example.backup:
# Set the absolute local path of the tar or ta.gz file that will be used as backup file
#   no default
#
# backup =

# example.batch:
# Set the absolute local path of the text file that will be used as batch file
#   no default
#
# batch =

[analytics]
# analytics:
# This section allows configuring analytics stuff

# analytics.enable_logging_runs:
# Activate analytics. By default, it is set to be the most privacy-friendly as possible.
# Look at the next options to relax it.
#   default = False
#
# enable_logging_runs = False

# analytics.disable_anonymous_analytics:
# User email in analytics is not anonymized if set to True.
#   possible values: True, False
# When set to False or not set, user email is replaced by the strategy chosen in analytics.anonymous_analytics entry.
# When set to True, the user email, is stored as it:
#   default = False
#
# disable_anonymous_analytics = False

# analytics.anonymous_analytics
#   possible values:
#   - group: The user email is replaced by:
#       - the first group name matching the email pattern(s) defined in the `[analytics_groups]` section, or
#       - an empty string if no match is found (or defined)
#     You need to define group 'a priori'
#   - full_hash: the email is replaced by its sha1 hash.
#     It allows producing unique visitor statistics, but group statistics is impossible based on domain name
#   - left_hash: the left part of the email (left part of the @) is replaced by its sha1.
#     It allows producing unique visitor statistics while keeping group information in clear for without 'a priori' analysis
#   - dual_hash: as left_hash, but the right part of the email (right part of the @) is also replaced by its sha1
#     It allows producing unique visitor statistics and having an anonymous group information but with 'a priori' this time
#   default = group
#
# anonymous_analytics = group

[analytics_groups]
# analytics_groups:
# This section allows defining groups matching email pattern for anonymous analytics.
# Entries are free and must follow this syntax:
#    <group> = <regex pattern>
# <group> is case-insensitive and can contain spaces, whereas <regex pattern> are case-sensitive
# The first matched pattern will be used to assign the group.
#
# In the following example:
#   [analytics_groups]
#   INRAE = ^.*@(.*\.)?inrae?\.fr$
#   Other = ^.*$\
#
# Email from 'inrae.fr' or 'inra.fr' domains will be part of the 'INRAE' group.
# Anything else will be part of 'Other' group.
# As groups names are case-insensitive, 'INRAE' will be stored as 'inrae' in database, and 'Other' as 'other'.

[legal]
# legal:
# This section allows configuring legal stuff like cookie wall and legal pages.
# This section concerns only the webserver mode.
# Apart the reserved 'cookie_wall' entry, all entries are free

# legal.cookie_wall:
#   When set with a non-empty string, will make a cookie wall appears on D-Genies website with the registered string.
#   no default
#
# Example:
#    [legal]
#    cookie_wall = D-Genies uses essential cookies in order to work, as described in <a href='/legal/cookies'>Cookies policy page</a>.
#
# cookie_wall =

# legal.*:
# Apart the reserved 'cookie_wall' entry, all entries are free must follow this syntax:
#   <page name> = </path/to/my/page.md>
# where:
#   - <page name> will be registered in 'Legal' menu on D-Genies website following the order set in this section,
#   - </path/to/my/page.md> is a markdown file.
# The '<web_url>/legal/<page name>' will display the content of '</path/to/my/page.md>'.
#
# Example:
#    [legal]
#    Cookies = /dgenies/md/cookies.md
#
# Here we set a cookie wall that invite user to read the Cookie Policy stored in /dgenies/md/cookies.md
