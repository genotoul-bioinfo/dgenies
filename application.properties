[global]
config_dir = ###USER###/.dgenies
upload_folder = /tmp/dgenies
data_folder = ###CONFIG###/data

# batch system type: local, sge, slurm
batch_system_type = local

web_url = http://localhost:5000

# Max size of uploaded files (also for files from URL, size uncompressed):
# Please set the unit: M for Megabyte or G for Gigabyte (-1 without unit to don't set a limit)
max_upload_size = 3G
# Max upload file size for all-vs-all (only target):
# Please set the unit: M for Megabyte or G for Gigabyte (-1 without unit to don't set a limit)
max_upload_size_ava = 1G
# Max upload file size (compressed or not, only for uploaded files, not from URL):
# Please set the unit: M for Megabyte or G for Gigabyte (-1 without unit to don't set a limit)
max_upload_file_size = 1G


[debug]
# Debug (enable only for tests)
enable = False
log_dir = ###CONFIG###/logs
# List of allowed IPs for tests, comma separated:
allowed_ip_tests =


[cluster]
drmaa_lib_path = ###SET_IT###
#Native specs: options passed to the scheduler
### Slurm: --mem-per-cpu={0} --ntasks={1} --time={2}
### SGE: -l mem={0},h_vmem={0} -pe parallel_smp {1}
### Note: copy&paste specifications for your scheduler. You can customize it.
### Always use {0} for memory, {1} for number of CPUs ({2} for duration time if slurm). All are required.
### If you don't want to change anything, don't edit anything.
native_specs = ###DEFAULT###

# If batch_system_type is not local, small jobs can be still run locally.
# Set to 0 to run all jobs on the cluster
max_run_local = 10
max_wait_local = 5

# To run only big jobs on the cluster, set the min query and target size (if max_run_local is reached, these parameters are ignores):
# Default parameters is for jobs that runs in approx. more than 3-4 minutes and consume approx. more than 9 GO of RAM
# Please set the unit: M for Megabyte or G for Gigabyte
min_query_size = 500M
min_target_size = 700M

prepare_script = ###PROGRAM###/bin/all_prepare.py
python3_exec = python3
# Max memory:
memory = 32
# Max memory for all-vs-all mode:
memory_ava = 32


[database]
type = sqlite
url = ###USER###/.dgenies/database.sqlite
# Not used for sqlite:
port = 3306
db =
user =
password =


[mail]
status = mail@dgenies
reply = mail@dgenies
org = "Dgenies team"
send_mail_status = True


[cron]
### Menage
# Time to launch the cron:
clean_time = 1h00
# Frequency (days):
clean_freq = 1


[jobs]
# Number of parallel runs for local jobs:
run_local = 1
data_prepare = 2
max_concurrent_dl = 5

[example]
query =
target =

[analytics]
enable_logging_runs = False
